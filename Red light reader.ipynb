{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff263e26-e9f7-4594-85aa-1de1abe0e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python mediapipe screen-brightness-control numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610df650-e8d0-4381-ac7e-6e7d6bbd866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import screen_brightness_control as sbc\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import winsound\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba4752-83cb-40b7-8e99-f5a861771e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize MediaPipe FaceMesh ---\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce711e0-8a1a-4b2c-b1b1-1cbe107c88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Webcam feed ---\n",
    "\n",
    "\n",
    "print(\"Press 'q' to quit.\")\n",
    "# Set frame count\n",
    "frame_count = 0\n",
    "MAX_FRAMES = 100  # Runs for ~100 frames (~5-6 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcec7a4-8933-4448-bdca-7913bfd430b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define eye landmark indices---\n",
    "LEFT_EYE = [33, 133, 160, 159, 158, 157, 173]\n",
    "RIGHT_EYE = [362, 263, 387, 386, 385, 384, 398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff7dc1-1cd4-42f2-8351-72394b372a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Lighting thresholds ---\n",
    "CONTRAST_THRESHOLD = 30\n",
    "GLARE_THRESHOLD = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64075c33-526f-4fdf-befd-07324c27a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    warning = \"\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        lm = results.multi_face_landmarks[0]\n",
    "        points = [(int(p.x * w), int(p.y * h)) for p in lm.landmark]\n",
    "\n",
    "        def crop_eye(indices):\n",
    "            pts = np.array([points[i] for i in indices])\n",
    "            x, y, ww, hh = cv2.boundingRect(pts)\n",
    "            # Clamp to image bounds\n",
    "            x = max(x, 0)\n",
    "            y = max(y, 0)\n",
    "            if x + ww > frame.shape[1] or y + hh > frame.shape[0]:\n",
    "                return None  # invalid crop\n",
    "            \n",
    "            return frame[y:y+hh, x:x+ww]\n",
    "\n",
    "        left_eye = crop_eye(LEFT_EYE)\n",
    "        right_eye = crop_eye(RIGHT_EYE)\n",
    "\n",
    "        def glare_score(eye_img):\n",
    "            gray = cv2.cvtColor(eye_img, cv2.COLOR_BGR2GRAY)\n",
    "            return np.mean(gray)\n",
    "\n",
    "# Check for valid eye crops before processing\n",
    "        if (\n",
    "            left_eye is not None and right_eye is not None and\n",
    "            left_eye.size > 0 and right_eye.size > 0\n",
    "        ):\n",
    "            avg_glare = (glare_score(left_eye) + glare_score(right_eye)) / 2\n",
    "            contrast = np.std(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "            \n",
    "            msg = f\"Contrast: {contrast:.1f} | Glare: {avg_glare:.1f}\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    # Decision logic\n",
    "            if contrast < CONTRAST_THRESHOLD:\n",
    "                warning = \"Ambient lighting too low!\"\n",
    "            elif avg_glare > GLARE_THRESHOLD:\n",
    "                warning = \"High screen glare!\"\n",
    "            if warning:\n",
    "                cv2.putText(frame, warning, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        else:\n",
    "    # Eye detection failed\n",
    "            msg = \"Cannot detect face or eyes!\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        for i in LEFT_EYE + RIGHT_EYE:\n",
    "            cv2.circle(frame, points[i], 2, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Red Light Reader\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f8152-c5ea-4ec6-9aa9-8324cf8181c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "last_warning = None\n",
    "last_sound_time = 0\n",
    "SOUND_COOLDOWN = 1 \n",
    "\n",
    "def play_warning_sound():\n",
    "    frequency = 500  # Hertz\n",
    "    duration = 100    # milliseconds\n",
    "    winsound.Beep(frequency, duration)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    warning = \"\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        lm = results.multi_face_landmarks[0]\n",
    "        points = [(int(p.x * w), int(p.y * h)) for p in lm.landmark]\n",
    "\n",
    "        def crop_eye(indices):\n",
    "            pts = np.array([points[i] for i in indices])\n",
    "            x, y, ww, hh = cv2.boundingRect(pts)\n",
    "            # Clamp to image bounds\n",
    "            x = max(x, 0)\n",
    "            y = max(y, 0)\n",
    "            if x + ww > frame.shape[1] or y + hh > frame.shape[0]:\n",
    "                return None  # invalid crop\n",
    "            \n",
    "            return frame[y:y+hh, x:x+ww]\n",
    "\n",
    "        left_eye = crop_eye(LEFT_EYE)\n",
    "        right_eye = crop_eye(RIGHT_EYE)\n",
    "\n",
    "        def glare_score(eye_img):\n",
    "            gray = cv2.cvtColor(eye_img, cv2.COLOR_BGR2GRAY)\n",
    "            return np.mean(gray)\n",
    "\n",
    "# Check for valid eye crops before processing\n",
    "        if (\n",
    "            left_eye is not None and right_eye is not None and\n",
    "            left_eye.size > 0 and right_eye.size > 0\n",
    "        ):\n",
    "            avg_glare = (glare_score(left_eye) + glare_score(right_eye)) / 2\n",
    "            contrast = np.std(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "            \n",
    "            msg = f\"Contrast: {contrast:.1f} | Glare: {avg_glare:.1f}\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    # Decision logic\n",
    "            if contrast < CONTRAST_THRESHOLD:\n",
    "                warning = \"WARNING: Ambient lighting too low!\"\n",
    "            elif avg_glare > GLARE_THRESHOLD:\n",
    "                warning = \"WARNING: High screen glare!\"\n",
    "            else:\n",
    "                warning = None\n",
    "            \n",
    "            if warning:\n",
    "                current_time = time.time()\n",
    "                \n",
    "                if warning != last_warning or (current_time - last_sound_time) > SOUND_COOLDOWN:\n",
    "                    play_warning_sound()\n",
    "                    last_sound_time = current_time\n",
    "                    last_warning = warning\n",
    "                    \n",
    "                cv2.rectangle(frame, (5,60), (500,90),(0,0,0), -1)\n",
    "                cv2.putText(frame, warning, (10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                \n",
    "                play_warning_sound()\n",
    "            \n",
    "            else:\n",
    "                last_warning = None\n",
    "        \n",
    "        else:\n",
    "    # Eye detection failed\n",
    "            msg = \"WARNING: Unable to detect face or eyes!\"\n",
    "            cv2.putText(frame, msg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        for i in LEFT_EYE + RIGHT_EYE:\n",
    "            cv2.circle(frame, points[i], 2, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Red Light Reader\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e65b2-68d2-4e4d-81b6-1f49623c839d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
